import os
import streamlit as st
from google import genai
from google.genai.types import HttpOptions

# â”€â”€â”€ Streamlit page setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="LLM Agent", layout="wide")

# â”€â”€â”€ Gemini configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    st.error("ğŸ”‘ Please set the GEMINI_API_KEY environment variable and restart.")
    st.stop()

# Use the Gen AI SDK client in â€œexpressâ€ mode (with just API key):
client = genai.Client(vertexai=True, api_key=API_KEY)

# â”€â”€â”€ Session memory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "history" not in st.session_state:
    st.session_state.history = []  # list of (role, message) tuples

# â”€â”€â”€ LLM call helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ask_gemini(question: str) -> str:
    # Build the chat history in Geminiâ€™s â€œchatâ€ format:
    messages = []
    for role, msg in st.session_state.history:
        messages.append({"role": role, "content": msg})
    messages.append({"role": "user", "content": question})

    # Call the Gemini model:
    resp = client.models.generate_content(
        model="gemini-2.0-flash-001",      # adjust to your exact model name
        contents=messages
    )
    return resp.text

# â”€â”€â”€ UI: Chat Input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ™ï¸ LLM Agent")
user_input = st.text_input("Your question:", key="input")
if st.button("Send") and user_input:
    st.session_state.history.append(("user", user_input))
    with st.spinner("ğŸ¤– Thinking..."):
        bot_response = ask_gemini(user_input)
    st.session_state.history.append(("assistant", bot_response))
    st.session_state.input = ""

# â”€â”€â”€ Render the conversation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for role, msg in st.session_state.history:
    if role == "user":
        st.markdown(f"**You:** {msg}")
    else:
        st.markdown(f"**Agent:** {msg}")
